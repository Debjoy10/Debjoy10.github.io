[{"authors":null,"categories":null,"content":"I am a B.Tech + M.Tech (Dual Degree) student at IIT Kharagpur, currently in my fifth year, pursuing joint degrees in Electronics and Computer Science.\nBroadly, my research interests lie in machine learning for image, language and speech processing. Previously, I have interned at KLA India Software, working on Neural Architecture Search for image classification and the Language Technology Group at Universit√§t Hamburg, where I worked on Multimodal Dubbing.\n  Download my resum√©.\n Contact me at sahadebjoy10@gmail.com\n","date":1667779200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1667779200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I am a B.Tech + M.Tech (Dual Degree) student at IIT Kharagpur, currently in my fifth year, pursuing joint degrees in Electronics and Computer Science.\nBroadly, my research interests lie in machine learning for image, language and speech processing.","tags":null,"title":"Debjoy Saha","type":"authors"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Wowchemy\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"a8edef490afe42206247b6ac05657af0","permalink":"/talk/example-talk/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example-talk/","section":"event","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"event"},{"authors":["Shravan Nayak","Christian Schuler","Debjoy Saha","Timo Baumann"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Create your slides in Markdown - click the Slides button to check out the example.   Supplementary notes can be added here, including [code, math, and images](https://wowchemy.com/docs/writing-markdown-latex/). --\r","date":1667779200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1667779200,"objectID":"d380633025824176690a692c2462d32b","permalink":"/publication/icmi/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/icmi/","section":"publication","summary":"This paper presents a comprehensive analysis of the neural audio-visual synchrony evaluation tool SyncNet.","tags":[],"title":"A Deep Dive Into Neural Synchrony Evaluation for Audio-visual Translation","type":"publication"},{"authors":["Debjoy Saha","Shravan Nayak","Timo Baumann"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Create your slides in Markdown - click the Slides button to check out the example.   Supplementary notes can be added here, including [code, math, and images](https://wowchemy.com/docs/writing-markdown-latex/). --\r","date":1655683200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1655683200,"objectID":"64825dbb9c1ee74bffad8fb827f62e4c","permalink":"/publication/lrec/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/lrec/","section":"publication","summary":"We introduce the Merkel Podcast Corpus, an audio-visual-text corpus in German collected from 16 years of (almost) weekly Internet podcasts of former German chancellor Angela Merkel.","tags":[],"title":"Merkel Podcast Corpus: A Multimodal Dataset Compiled from 16 Years of Angela Merkel's Weekly Video Podcasts","type":"publication"},{"authors":["Debjoy Saha","Naman Paharia","Debajit Chakraborty","Punyajoy Saha","Animesh Mukherjee"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Create your slides in Markdown - click the Slides button to check out the example.   Supplementary notes can be added here, including [code, math, and images](https://wowchemy.com/docs/writing-markdown-latex/). --\r","date":1621555200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1621555200,"objectID":"78f44aa89c9d06c0018b9de0da435093","permalink":"/publication/eacl-dravidian/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/eacl-dravidian/","section":"publication","summary":"We present an exhaustive exploration of different transformer and fusion models and a genetic algorithm ensembling technique for Offensive Language Identification in Dravidian Languages.","tags":[],"title":"Ensembling strategies for Transformer-based Offensive language Detection","type":"publication"},{"authors":null,"categories":null,"content":"In our work, we study robust ensembling techniques for offensive language identification in code-mixed Dravidian languages using multilingual BERT models. Owing to the stochastic nature of neural net predictions, ensembling over multiple models reduces variance, thus improving low resource performance of these models. In our current approach, we look at 3 major ensembling techniques, namely,\n Genetic algorithm optimised weighted averaging, Self-Ensembling with different random seeds and CNN-BERT embedding fusion, in which we train a classifier on concatenated embeddings for different BERT models and CNN embeddings trained on performant word vectors.  We experiment with models pretrained on code-mixed datasets. We also look at some ways to combat class imbalance in the dataset through collated 2-step training and weighted gradients. We study methods for robust ensembling of transformer and convolutional models for classification of low resource languages. We conclusively show that a combination of multiple inter-model ensembling techniques can help reduce the variance of predictions and improve performance across all classes in low-resource settings.\n","date":1621555200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1621555200,"objectID":"c88b36fb080c2c8eaccd19444234ed0d","permalink":"/project/dravidian/","publishdate":"2021-05-21T00:00:00Z","relpermalink":"/project/dravidian/","section":"project","summary":"Shared Task at DravidianLangTech @ EACL 2021 conference.","tags":["Deep Learning","Natural Language Processing"],"title":"Low-Resource Offensive Language Detection","type":"project"},{"authors":["Debjoy Saha","Âê≥ÊÅ©ÈÅî"],"categories":["Demo","ÊïôÁ®ã"],"content":"Overview  The Wowchemy website builder for Hugo, along with its starter templates, is designed for professional creators, educators, and teams/organizations - although it can be used to create any kind of site The template can be modified and customised to suit your needs. It\u0026rsquo;s a good platform for anyone looking to take control of their data and online identity whilst having the convenience to start off with a no-code solution (write in Markdown and customize with YAML parameters) and having flexibility to later add even deeper personalization with HTML and CSS You can work with all your favourite tools and apps with hundreds of plugins and integrations to speed up your workflows, interact with your readers, and much more    The template is mobile first with a responsive design to ensure that your site looks stunning on every device.  Get Started  üëâ Create a new site üìö Personalize your site üí¨ Chat with the Wowchemy community or Hugo community üê¶ Twitter: @wowchemy @GeorgeCushen #MadeWithWowchemy üí° Request a feature or report a bug for Wowchemy ‚¨ÜÔ∏è Updating Wowchemy? View the Update Guide and Release Notes  Crowd-funded open-source software To help us develop this template and software sustainably under the MIT license, we ask all individuals and businesses that use it to help support its ongoing maintenance and development via sponsorship.\n‚ù§Ô∏è Click here to become a sponsor and help support Wowchemy\u0026rsquo;s future ‚ù§Ô∏è As a token of appreciation for sponsoring, you can unlock these awesome rewards and extra features ü¶Ñ‚ú®\nEcosystem  Hugo Academic CLI: Automatically import publications from BibTeX  Inspiration Check out the latest demo of what you\u0026rsquo;ll get in less than 10 minutes, or view the showcase of personal, project, and business sites.\nFeatures  Page builder - Create anything with widgets and elements Edit any type of content - Blog posts, publications, talks, slides, projects, and more! Create content in Markdown, Jupyter, or RStudio Plugin System - Fully customizable color and font themes Display Code and Math - Code highlighting and LaTeX math supported Integrations - Google Analytics, Disqus commenting, Maps, Contact Forms, and more! Beautiful Site - Simple and refreshing one page design Industry-Leading SEO - Help get your website found on search engines and social media Media Galleries - Display your images and videos with captions in a customizable gallery Mobile Friendly - Look amazing on every screen with a mobile friendly version of your site Multi-language - 34+ language packs including English, ‰∏≠Êñá, and Portugu√™s Multi-user - Each author gets their own profile page Privacy Pack - Assists with GDPR Stand Out - Bring your site to life with animation, parallax backgrounds, and scroll effects One-Click Deployment - No servers. No databases. Only files.  Themes Wowchemy and its templates come with automatic day (light) and night (dark) mode built-in. Alternatively, visitors can choose their preferred mode - click the moon icon in the top right of the Demo to see it in action! Day/night mode can also be disabled by the site admin in params.toml.\nChoose a stunning theme and font for your site. Themes are fully customizable.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1607817600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"279b9966ca9cf3121ce924dca452bb1c","permalink":"/post/getting-started/","publishdate":"2020-12-13T00:00:00Z","relpermalink":"/post/getting-started/","section":"post","summary":"Welcome üëã We know that first impressions are important, so we've populated your new site with some initial content to help you get familiar with everything in no time.","tags":["Academic","ÂºÄÊ∫ê"],"title":"Welcome to Wowchemy, the website builder for Hugo","type":"post"},{"authors":null,"categories":null,"content":"Worked as a part of Drone-Acharya Team, IIT Kharagpur for the Flipkart GRID-2.0 Robotics Track Competition: Autonomous Indoor Drone. Designed an Imitation-Learning based learning algorithm for fast Quadrotor trajectory planning using DAGGER. Fully deployed an expert minimum-snap trajectory generation algorithm on Microsoft AirSim Simulator on a custom warehouse environment built on Unreal Engine.\nHad a great experience at the National Finales of Flipkart GRID2.0!\nWill update with any new developments that come out of this project.\n","date":1599696000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1599696000,"objectID":"6f115c842dcb5a01b3e3bfefb9e5d765","permalink":"/project/grid/","publishdate":"2020-09-10T00:00:00Z","relpermalink":"/project/grid/","section":"project","summary":"Fast Quadrotor trajectory following for Flipkart GRID-2.0 Competition.","tags":["Deep Learning","Computer Vision","Robotics"],"title":"Drone Racing Optimisation","type":"project"},{"authors":null,"categories":null,"content":"The Problem Statement This project is aimed at identifying hateful content from social media memes. In general, hateful memes have a more convoluted hidden meaning, woven deep into our social prejudices. Seemingly insignificant differences can completely change how people interpret them. Due to the subtle nature of these memes, people belonging to different classes, societies and gender interpret them differently. All these qualities make the task of detection of hateful memes a lot more challenging and all the more necessary to ensure a safe and wholesome social media experience. In this project, we look into the challenges we face with brute force finetuning for this task and why training with semi-supervised modifications is a necessity.\nThe Model: The model we use for experiments is Visual-BERT, which is a transformer encoder based multimodal deep learning model, developed by UCLA-NLP. The model architecture is similar to BERT. The difference is that we also input meme-image embeddings(obtained from bounding boxes predicted by a Mask-RCNN model) concatenated to BERT‚Äôs WordPiece embeddings for the meme text. This ensures efficient text-to-image and image-to-text attention that ensures that we can model the subtle interdependencies at play when dealing with multiple modalities.\nFinetuning strategies:   Community Tags:\nWe perform image grounding in a self-supervised manner by extracting target community information from the meme image. We collect a Community-dataset comprising of images related to the top-10 targeted communities identified in the Hateful Memes dataset using browser automation. We develop a CNN classifier, which we call the CommNet, and train it on this dataset. After training, we generate the community tag output from CommNet for the entire Hateful Memes dataset.\nOutput labels with the prediction probability of less than a threshold are discarded. And for the rest, an additional line with information regarding the community information is added to the input meme text. This modified input is provided to the Visual-BERT model during training and inference. This helps the model get details regarding community information contained in the meme, and thus better differentiate between memes with similar text in different contexts.\n\n  Negative Supervision:\nOne noticeable feature of the Hatememe dataset was that multiple memes were based upon the same template images. In these cases, if there is a minimal lexical difference in the meme text, the Visual-BERT output [CLS] embeddings are similar, thus resulting in similar prediction probabilities.\nNegative supervision aims at learning to differentiate between similar-looking samples. First, we run the Visual-BERT model on each sample in the train split of the Hatememe dataset and store the CLS embeddings for hate and not hate samples separately. For storing, we use Facebook‚Äôs fast indexing-based storage FAISS. Then, we iterate on all samples in the training dataset and extract the samples having the opposite training label but the largest cosine similarity of their CLS embeddings. During training, we include an additional negative sampling loss, that is a scaled cosine similarity between the embeddings of the similar sample pair. This ensures that, as training progresses, similar samples having different labels have more distant output embeddings.\n\n  Monte Carlo Dropout: During inference, we keep random dropout and take the final predicted probability as the mean of the Gaussian distribution generated using the predicted probabilities over 100 runs. Using MC-dropout ensures better-calibrated output probabilities, i.e. generated probabilities reflect the true model confidence in the predicted class.\n  ","date":1598918400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1598918400,"objectID":"059ddc7021a752a6885d070520a343f2","permalink":"/project/hatememe/","publishdate":"2020-09-01T00:00:00Z","relpermalink":"/project/hatememe/","section":"project","summary":"Multimodal Machine Learning Project at CNERG-IITKGP","tags":["Deep Learning","Natural Language Processing"],"title":"Hateful Memes Detection","type":"project"},{"authors":["Debjoy Saha","Balaji Udayagiri","Parakh Agarwal","Biswajit Ghosh","Somesh Kumar"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Create your slides in Markdown - click the Slides button to check out the example.   Supplementary notes can be added here, including [code, math, and images](https://wowchemy.com/docs/writing-markdown-latex/). --\r","date":1570060800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570060800,"objectID":"f9bf65e3f60eff6126b0d4cfe5219a1a","permalink":"/publication/imav/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/imav/","section":"publication","summary":"The objective of this paper is the development of the computer vision tools for efficient inventory management of packages in a warehouse.","tags":[],"title":"Warehouse Management Using Real-Time QR-Code and Text Detection","type":"publication"},{"authors":null,"categories":null,"content":" Developed a algorithm for autonomous warehouse inventory management using UAVs for the 11th International Micro Aerial Vehicles competition and conference(IMAV-2019). Devised a traversal algorithm using coloured frames for localisation, for performing the complete inventory in minimum time on a DJI-Tello microdrone. Developed the OCR tools for accurate detection of alphanumeric codes using google‚Äôs Tesseract library and QR-codes using Zbar library for inventory management of boxes in a warehouse.\n Won the IMAV-2019 Indoor Competition! :)  ","date":1569974400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1569974400,"objectID":"05fe60ce55c76acdf1870440afa616c1","permalink":"/project/imav/","publishdate":"2019-10-02T00:00:00Z","relpermalink":"/project/imav/","section":"project","summary":"For IMAV-2019, Indoor Aerial Robotics competition held in Madrid, Spain","tags":["Computer Vision","Robotics"],"title":"Warehouse management using Quadrotors","type":"project"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot;\rif porridge == \u0026quot;blueberry\u0026quot;:\rprint(\u0026quot;Eating...\u0026quot;)\r  Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}}\r{{% fragment %}} **Two** {{% /fragment %}}\r{{% fragment %}} Three {{% /fragment %}}\r Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}}\r- Only the speaker can read these notes\r- Press `S` key to view\r{{% /speaker_note %}}\r Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/media/boards.jpg\u0026quot; \u0026gt;}}\r{{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}}\r{{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}\r  Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1,\r.reveal section h2,\r.reveal section h3 {\rcolor: navy;\r}\r  Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"}]